#!/usr/bin/env node
// scripts/test-intelligence.js - Teste de inteligÃªncia do modelo
import 'dotenv/config';
import { askLLM } from '../src/lib/llm.js';

const intelligenceTests = [
  {
    name: "ConsistÃªncia de Contexto",
    messages: [
      { role: 'system', content: 'VocÃª Ã© Fernando AI, um assistente inteligente.' },
      { role: 'user', content: 'Meu nome Ã© JoÃ£o e eu trabalho com vendas.' },
      { role: 'assistant', content: 'Prazer em conhecÃª-lo, JoÃ£o! Vendas Ã© uma Ã¡rea muito interessante.' },
      { role: 'user', content: 'Qual Ã© o meu nome e profissÃ£o que eu mencionei?' }
    ],
    expectedPattern: /joÃ£o.*venda/i,
    description: "Deve lembrar do nome (JoÃ£o) e profissÃ£o (vendas)"
  },
  
  {
    name: "RaciocÃ­nio MatemÃ¡tico", 
    messages: [
      { role: 'system', content: 'VocÃª Ã© Fernando AI, um assistente inteligente.' },
      { role: 'user', content: 'Se eu tenho 10 maÃ§Ã£s e como 3, depois compro mais 5, quantas maÃ§Ã£s tenho no total?' }
    ],
    expectedPattern: /12|doze/i,
    description: "Deve calcular: 10 - 3 + 5 = 12"
  },
  
  {
    name: "CompreensÃ£o de Contexto",
    messages: [
      { role: 'system', content: 'VocÃª Ã© Fernando AI, um assistente inteligente.' },
      { role: 'user', content: 'Estou fazendo um bolo de chocolate. Preciso de 3 ovos mas sÃ³ tenho 2.' },
      { role: 'user', content: 'O que devo fazer?' }
    ],
    expectedPattern: /comprar|ovo|falta|precisa/i,
    description: "Deve sugerir comprar ovos ou alternativa"
  },
  
  {
    name: "ConsistÃªncia de Personalidade",
    messages: [
      { role: 'system', content: 'VocÃª Ã© Fernando AI, um assistente inteligente.' },
      { role: 'user', content: 'Como vocÃª se chama?' }
    ],
    expectedPattern: /fernando|ai/i,
    description: "Deve responder consistentemente com o nome Fernando AI"
  },
  
  {
    name: "LÃ³gica Sequencial",
    messages: [
      { role: 'system', content: 'VocÃª Ã© Fernando AI, um assistente inteligente.' },
      { role: 'user', content: 'Complete a sequÃªncia: 2, 4, 6, 8, ?' }
    ],
    expectedPattern: /10|dez/i,
    description: "Deve identificar padrÃ£o e responder 10"
  }
];

async function runTest(test) {
  console.log(`\nğŸ§ª Testando: ${test.name}`);
  console.log(`ğŸ“‹ Esperado: ${test.description}`);
  
  try {
    const response = await askLLM(test.messages);
    const passed = test.expectedPattern.test(response);
    
    console.log(`ğŸ’¬ Resposta: "${response}"`);
    console.log(`${passed ? 'âœ…' : 'âŒ'} Resultado: ${passed ? 'PASSOU' : 'FALHOU'}`);
    
    return passed;
    
  } catch (error) {
    console.log(`âŒ Erro no teste: ${error.message}`);
    return false;
  }
}

async function main() {
  console.log('ğŸ¤– Fernando AI - Teste de InteligÃªncia\n');
  console.log('Testando capacidades cognitivas do modelo...\n');
  
  let passedTests = 0;
  const totalTests = intelligenceTests.length;
  
  for (const test of intelligenceTests) {
    const passed = await runTest(test);
    if (passed) passedTests++;
    
    // Pausa entre testes para nÃ£o sobrecarregar
    await new Promise(resolve => setTimeout(resolve, 2000));
  }
  
  console.log('\n' + '='.repeat(50));
  console.log(`ğŸ“Š RESULTADO FINAL: ${passedTests}/${totalTests} testes passaram`);
  
  const percentage = Math.round((passedTests / totalTests) * 100);
  console.log(`ğŸ¯ Taxa de sucesso: ${percentage}%`);
  
  let assessment;
  if (percentage >= 80) {
    assessment = 'ğŸŸ¢ EXCELENTE - Modelo muito inteligente';
  } else if (percentage >= 60) {
    assessment = 'ğŸŸ¡ BOM - Modelo funcionando adequadamente';
  } else if (percentage >= 40) {
    assessment = 'ğŸŸ  REGULAR - Modelo com algumas limitaÃ§Ãµes';
  } else {
    assessment = 'ğŸ”´ RUIM - Modelo precisa de ajustes';
  }
  
  console.log(`ğŸ“ˆ AvaliaÃ§Ã£o: ${assessment}`);
  
  if (percentage < 60) {
    console.log('\nğŸ’¡ SUGESTÃ•ES DE MELHORIA:');
    console.log('  â€¢ Verificar se o modelo estÃ¡ funcionando corretamente');
    console.log('  â€¢ Considerar usar modelo mais avanÃ§ado');
    console.log('  â€¢ Ajustar parÃ¢metros de temperatura (mais baixo = mais preciso)');
    console.log('  â€¢ Verificar se hÃ¡ interferÃªncia de outros prompts');
  }
  
  console.log('\nğŸ”§ Para melhorar a inteligÃªncia:');
  console.log('  â€¢ TEMPERATURE=0.3 (mais preciso)');
  console.log('  â€¢ MAX_HISTORY_MESSAGES=100 (mais contexto)');
  console.log('  â€¢ TOP_P=0.85 (respostas mais focadas)');
}

main().catch(error => {
  console.error('ğŸ’¥ Erro fatal:', error);
  process.exit(1);
});
